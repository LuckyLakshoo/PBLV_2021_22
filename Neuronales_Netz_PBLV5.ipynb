{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Neuronales Netz PBLV5.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Neural network for segmentation of welds\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "IdOf-UZC0Lh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### From Mario Bartolvic, Hamza Mani and Viet Phuoc Ho"
      ],
      "metadata": {
        "id": "vAK4xF_32D3e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Requirements"
      ],
      "metadata": {
        "id": "Jn9LKCxr1eE7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install git+https://github.com/divamgupta/image-segmentation-keras tqdm opencv-python"
      ],
      "metadata": {
        "id": "vssfRFp41oSI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Imports"
      ],
      "metadata": {
        "id": "jxrfEvVt1J_W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from IPython.display import Image\n",
        "from keras_segmentation.models.unet import unet\n",
        "from keras_segmentation.models.segnet import segnet\n",
        "from keras_segmentation.models.fcn import fcn_32"
      ],
      "metadata": {
        "id": "OushZgBi1X5z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JpVgw4szckFI"
      },
      "source": [
        "### Initialize the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-l3Lzy5nDqCw"
      },
      "source": [
        "model = unet(n_classes=2)\n",
        "#model = segnet(n_classes=2)\n",
        "#model = fcn_32(n_classes=2)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Image preprocessing"
      ],
      "metadata": {
        "id": "ExfqGCEQ3R8a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for file in os.listdir(\"train/masks/\"): # replace paths\n",
        "  img = cv2.imread(os.path.join(\"train/masks\", file), cv2.IMREAD_GRAYSCALE)\n",
        "  normalizedImg = np.zeros((800, 800))\n",
        "  normalizedImg = cv2.normalize(img,  normalizedImg, 0, 1, cv2.NORM_MINMAX)\n",
        "  \n",
        "  if img is not None:\n",
        "    cv2.imwrite(os.path.join(\"train/masks\", file), normalizedImg)"
      ],
      "metadata": {
        "id": "IAaDBhTc3WaX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qGd_TDGKcdL7"
      },
      "source": [
        "### Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jXKtRFd9EC0K"
      },
      "source": [
        "model.train(\n",
        "    train_images =  \"train/images/\",\n",
        "    train_annotations = \"train/masks/\",\n",
        "    checkpoints_path = \"/weights/unet_1\" , \n",
        "    epochs=10,\n",
        "    steps_per_epoch=500,\n",
        "    val_steps_per_epoch=500,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluation of the model "
      ],
      "metadata": {
        "id": "GQ9b67Yi3kZF"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U0muKcNEDy6N"
      },
      "source": [
        "for index in tqdm(range(0, 19)):\n",
        "  out = model.predict_segmentation(\n",
        "      inp=f\"test/images/{index}.png\",\n",
        "      out_fname=f\"out/{index}_out.png\"\n",
        "  )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Result visualisation "
      ],
      "metadata": {
        "id": "mStqkC1w34HX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img_out = cv2.imread(\"test/2_out.png\", 0)\n",
        "img_mask = cv2.imread(\"test/2_real.png\", 0)\n",
        "mask = np.zeros((800, 800))\n",
        "out = cv2.normalize(img_out,  mask, 0, 1, cv2.NORM_MINMAX)\n",
        "real = cv2.normalize(img_mask,  mask, 0, 1, cv2.NORM_MINMAX)"
      ],
      "metadata": {
        "id": "sn4ptrRUmVC9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = out.copy()\n",
        "true_pos = 0\n",
        "false_pos = 0\n",
        "for outer_index, outer in enumerate(real):\n",
        "  for inner_index, inner in enumerate(outer):\n",
        "    if inner == 1: # needs to be background\n",
        "      if out[outer_index][inner_index] == 1: # prediction correct\n",
        "        result[outer_index][inner_index] = 255\n",
        "      elif out[outer_index][inner_index] == 0: # detected to much\n",
        "        result[outer_index][inner_index] = 150\n",
        "    elif inner == 0: # should be prediction \n",
        "      if out[outer_index][inner_index] == 0: # prediction correct\n",
        "        result[outer_index][inner_index] = 0\n",
        "        true_pos += 1\n",
        "      elif out[outer_index][inner_index] == 1: # not detected\n",
        "        result[outer_index][inner_index] = 75\n",
        "        false_pos += 1"
      ],
      "metadata": {
        "id": "4XODK_tciYwi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction = true_pos/(true_pos + false_pos)\n",
        "prediction"
      ],
      "metadata": {
        "id": "KYh4sg0C6ypb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lab = cv2.cvtColor(result, cv2.COLOR_GRAY2RGB)\n",
        "\n",
        "correct = lab[100][100].copy()\n",
        "correct[0] = 255\n",
        "correct[1] = 0\n",
        "correct[2] = 0\n",
        "\n",
        "much = lab[100][100].copy() # detected to much\n",
        "much[0] = 0\n",
        "much[1] = 255\n",
        "much[2] = 0\n",
        "\n",
        "less = lab[100][100].copy() # not detected\n",
        "less[0] = 0\n",
        "less[1] = 0\n",
        "less[2] = 255\n",
        "\n",
        "for outer_index, outer in enumerate(result):\n",
        "  for inner_index, inner in enumerate(outer):\n",
        "    if 0 in lab[outer_index][inner_index]:\n",
        "      lab[outer_index][inner_index] = correct\n",
        "    elif 150 in lab[outer_index][inner_index]:\n",
        "      lab[outer_index][inner_index] = much\n",
        "    elif 75 in lab[outer_index][inner_index]:\n",
        "      lab[outer_index][inner_index] = less\n",
        "\n",
        "img_mask = cv2.imwrite(\"test/result.png\", lab)"
      ],
      "metadata": {
        "id": "v8DlBVS1mf3Y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}